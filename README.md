# Roam Semantic Search Stack

This repository packages everything needed to run the Roam Semantic Search backend and front-end extension. It ingests your Roam graph into Weaviate using VoyageAI embeddings, exposes a FastAPI service for search and sync, and ships a Roam Depot compatible extension that provides the UI inside Roam.

The goal of this guide is to help a production user go from an empty machine to a working deployment.

## Architecture Overview
- **Roam Semantic Backend (`backend/main_semantic.py`)** – FastAPI service that runs the sync pipeline, talks to the chunker, embeds with VoyageAI, and writes/query Weaviate. Exposes `/sync/*` management endpoints and `/search` for the extension.
- **Chunker microservice (`backend/chunker_service.py`)** – Keeps a warm `chonkie` semantic chunker process so the pipeline can cut Roam pages into semantically coherent sections.
- **Weaviate** – Vector database (self-hosted container) storing `RoamSemanticChunks`. Uses the VoyageAI reranker module for hybrid search.
- **Roam extension (`roam-semantic-search/extension.js`)** – Runs inside Roam. Lets you trigger syncs, monitor status, and perform hybrid semantic search against the backend.
- **Persistent state (`backend/data/semantic_sync.db`)** – SQLite cache so incremental syncs can resume quickly.

A typical request path:
1. Sync job pulls pages from the Roam Backend API using your graph token.
2. Text is linearised, chunked via the chunker microservice, embedded with VoyageAI, and batch-written to Weaviate.
3. Roam extension queries `/search`, which embeds the query with VoyageAI, runs Weaviate hybrid + optional rerank, and returns formatted results with block context.

## Prerequisites

### Accounts & API keys
You must provision the following before deploying:
- **Roam graph token** – Generated by a graph admin under *Settings ▸ Graph ▸ API Tokens*. Needs `read+edit` or `read-only` scope. The backend reads from Roam and uses this token for both sync and live context pulls.
- **VoyageAI API key** – Sign up at [https://www.voyageai.com](https://www.voyageai.com) and create an API key that has access to the `voyage-context-3` embedding model and the `rerank-2-lite` reranker. The key is used by:
  - The sync pipeline (`VoyageEmbeddingClient`) for document embeddings.
  - Weaviate reranker module (forwarded via `X-VoyageAI-Api-Key`).
  - The chunker service when `CHUNKER_EMBEDDING_PROVIDER=voyageai`.
- **Google Generative AI key (placeholder acceptable)** – The settings model currently requires `GOOGLE_API_KEY`. The service does not call Google today, so a dummy value such as `dummy` is fine, but the environment variable must exist.

Optional but recommended:
- **Reverse proxy / TLS certificates** if you intend to expose the backend publicly.

### Tooling on the host
- Docker Engine ≥ 24.x
- Docker Compose v2 (`docker compose` CLI)
- Make sure outbound HTTPS is permitted so containers can pull images and the chunker can download the IBM Granite model (or call VoyageAI).

## Configuration

1. Copy `.env` and replace placeholders with your own secrets. Treat this file as sensitive.

   ```bash
   cp .env .env.production
   ```

2. Edit the file and keep only placeholder values, for example:

   ```dotenv
   # Roam API
   ROAM_GRAPH_NAME=your-graph-slug
   ROAM_API_TOKEN=roam-graph-token-XXXXXXXXXXXXXXXXXXXXXXXX

   # Embeddings
   VOYAGEAI_API_KEY=sk-your-voyage-key
   GOOGLE_API_KEY=dummy-or-your-key

   # Service wiring
   WEAVIATE_HTTP_HOST=weaviate
   WEAVIATE_GRPC_HOST=weaviate
   CHUNKER_SERVICE_URL=http://chunker:8003

   # Chunker tuning (optional overrides)
   CHUNKER_EMBEDDING_PROVIDER=voyageai
   CHUNKER_VOYAGE_MODEL=voyage-3-lite
   CHUNKER_MODEL=ibm-granite/granite-embedding-small-english-r2
   CHUNKER_THRESHOLD=0.6
   CHUNKER_CHUNK_SIZE=800
   CHUNKER_SKIP_WINDOW=1
   CHUNKER_MIN_CHUNK_SIZE=50

   # Pipeline tuning (optional)
   ROAM_MAX_REQUESTS_PER_MINUTE=50
   CHUNKER_CONCURRENCY=1
   CHUNKER_GROUP_SIZE=16
   VOYAGE_CONCURRENCY=4
   WEAVIATE_WRITE_CONCURRENCY=1
   SEMANTIC_SYNC_DB=/app/data/semantic_sync.db
   SYNC_STATE_FILE=/app/data/sync_state.json
   ```

   > **Note:** `SEMANTIC_SYNC_DB` and `SYNC_STATE_FILE` default to files under `backend/data/`. Persist that directory to keep incremental state across container restarts.

3. Point Docker Compose at your customised env file, e.g. `export COMPOSE_FILE=docker-compose.yml` and `export COMPOSE_ENV_FILE=.env.production`, or rename `.env.production` back to `.env`.

## Building & Running the stack

1. Build images (first run or after dependency changes):
   ```bash
   docker compose build weaviate chunker backend-semantic
   ```

2. Launch the core services:
   ```bash
   docker compose up -d weaviate chunker backend-semantic
   ```

   - `weaviate` listens on `8080` (HTTP) and `50051` (gRPC) and stores data in `./weaviate_data`.
   - `chunker` exposes port `8003` (`http://localhost:8003/health`).
   - `backend-semantic` serves FastAPI on `http://localhost:8002` (container port `8000`).

3. Confirm everything is healthy:
   ```bash
   curl http://localhost:8003/health          # chunker ready
   curl http://localhost:8002/                # backend handshake (shows graph + document count)
   docker compose logs -f chunker backend-semantic weaviate
   ```

   The first chunker start may download models; expect a short delay.

> ⚙️ **Production tip:** The Compose file starts FastAPI with `--reload` and mounts the source directory for local development. Swap the command for `uvicorn main_semantic:app --host 0.0.0.0 --port 8000 --workers 2` and remove the bind mount for a leaner production container.

## Populating Weaviate

1. Trigger an initial full sync (requires the chunker to be healthy):
   ```bash
   curl -X POST http://localhost:8002/sync/start \
     -H 'Content-Type: application/json' \
     -d '{"mode": "full", "recreate_collection": true}'
   ```

   - `mode` can be `full`, `since`, or `limit` (test run against the first *n* pages).
   - `recreate_collection` drops and rebuilds `RoamSemanticChunks` – use this for the very first sync.
   - `clear` deletes existing objects before reloading.

2. Monitor progress:
   ```bash
   watch -n5 curl -s http://localhost:8002/sync/status | jq
   ```

   The status payload includes per-stage counters, durations, and any failures. Jobs run in the background; only one sync can run at a time.

3. Cancel a stuck job if needed:
   ```bash
   curl -X POST http://localhost:8002/sync/cancel
   ```

4. Incremental updates:
   - Run `mode: "since"` on a schedule. If you omit the `since` timestamp, the backend reuses the last `max_edit_time` captured in the run summary.
   - Persist `backend/data/` so the SQLite cache (`semantic_sync.db`) can help skip unchanged pages.
   - The `/sync/start` payload accepts `state_file` and `resume` for long-running syncs.

## Installing the Roam extension

1. Open `roam-semantic-search/extension.js` and copy the contents.
2. In Roam, either:
   - Paste the script under a `{{[[roam/js]]}}` block, **or**
   - Host it somewhere (GitHub Gist, CDN) and reference it via a `<script>` tag as per [Roam Depot docs](docs/external/roam_research/roam-extension-docs.md).
3. After the script loads, open the extension settings:
   - Command Palette → “Semantic Search: Open Settings”, or use Roam Depot’s settings pane.
   - Set **Backend URL** to your deployment (e.g. `http://localhost:8002` or your HTTPS domain).
   - Adjust result limits, debounce, and toggles (`Hide Page Results`, `Use VoyageAI Rerank`, `Search Alpha`).
4. Use the built-in buttons to:
   - **Test Connection** – calls `/` and confirms collection count.
   - **Sync Recently Edited Pages / Full Sync** – proxies the `/sync/start` API.
   - **Clear Database** – drops the Weaviate collection via `/sync/clear` (destructive).
5. Launch the search modal: Command Palette → “Semantic Search”. Results support keyboard navigation, filtering, reranking, and linking back to Roam blocks.

## Operating in production

- **Security** – Place the FastAPI service behind an authenticated reverse proxy. Lock down ports 8002 and 8003 to trusted networks. Store API keys in a secrets manager rather than committing them to the repo.
- **TLS** – Terminate HTTPS in a proxy (nginx, Caddy, Traefik) and forward to the backend. Update the extension’s backend URL accordingly.
- **Scheduling syncs** – Use cron or an automation platform to POST to `/sync/start` on intervals (e.g. hourly `since` sync). A simple example: `curl -X POST https://backend.example.com/sync/start -d '{"mode":"since"}'`.
- **Backups** – Snapshot `weaviate_data/` and `backend/data/` regularly. The latter holds sync history and state.
- **Monitoring** – Watch container logs for `Voyage embedding failed` or Roam API rate-limit messages. Consider scraping `/sync/status` and `uvicorn` metrics.
- **Resource sizing** – Embedding large graphs is CPU and network intensive. Ensure the host has enough CPU/RAM and allows outbound HTTPS calls to `api.roamresearch.com` and `api.voyageai.com`.

## Troubleshooting

- **401 / 403 from Roam** – Re-issue the graph token and verify the `ROAM_GRAPH_NAME` matches the slug shown in the Roam URL. Tokens must be prefixed with `roam-graph-token-` and sent as `Bearer`.
- **VoyageAI errors** – Check quota and model access. If you prefer to avoid API calls in the chunker, switch `CHUNKER_EMBEDDING_PROVIDER=granite` (no API key needed) and restart.
- **Chunker health fails** – First launch downloads models; watch `docker compose logs chunker`. Ensure the container has enough RAM (~2 GB recommended).
- **Weaviate rejects writes** – Confirm the `reranker-voyageai` module is enabled and the FastAPI client is attaching `X-VoyageAI-Api-Key`. Re-run with `recreate_collection` if the schema drifted.
- **Extension cannot reach backend** – Browser must reach your backend URL over HTTPS if Roam is served over HTTPS. Configure CORS or host the backend under the same domain.
- **State not persisting** – Mount `backend/data/` to a durable volume. Otherwise each container restart forces a fresh sync.

## Reference & Further Reading

- Backend source: `backend/` (see `main_semantic.py`, `sync_semantic.py`, `semantic_sync/`).
- Roam extension: `roam-semantic-search/extension.js`.
- Roam API docs: `docs/external/roam_research/roam-backend-api.md`.
- VoyageAI context models: `docs/external/voyageai/context-model-guide.md`.
- Chunker service (`chonkie`) configuration: `backend/chunker_service.py`.

Feel free to adapt Docker Compose or deploy the services on your own orchestration platform. The key requirements are:
1. FastAPI backend with the env vars above.
2. Accessible chunker service.
3. Weaviate with `reranker-voyageai` enabled and persistent storage.
4. Roam extension pointing at your backend URL.
