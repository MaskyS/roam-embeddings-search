# Roam Semantic Search Stack

This repository packages everything needed to run the Roam Semantic Search backend and front-end extension. It ingests your Roam graph into Weaviate using VoyageAI embeddings, exposes a FastAPI service for search and sync, and ships a Roam Depot compatible extension that provides the UI inside Roam.

The goal of this guide is to help a production user go from an empty machine to a working deployment.

## Architecture Overview
- **Search + Sync API (`backend/services/search_service.py`)** – FastAPI service that runs the semantic sync, talks to the chunker, embeds with VoyageAI, and writes/queries Weaviate. Exposes `/sync/*` management endpoints and `/search` for the extension.
- **Chunker microservice (`backend/services/chunker_service.py`)** – Keeps a warm `chonkie` semantic chunker process so the pipeline can cut Roam pages into semantically coherent sections.
- **Weaviate** – Vector database (self‑hosted container) storing `RoamSemanticChunks`. Uses the VoyageAI reranker module for hybrid search.
- **Roam extension (`roam-semantic-search/extension.js`)** – Runs inside Roam. Lets you trigger syncs, monitor status, and perform hybrid semantic search against the backend.
- **Persistent state (`backend/data/semantic_sync.db`)** – SQLite cache backing incremental sync and run history.

A typical request path:
1. Sync job lists page UIDs from the Roam Backend API using your graph token.
2. Metadata prepass fetches each page's max edit time (and title) and filters out unchanged pages.
3. Pages with children are fully pulled and linearised; childless pages use their title only (no extra pull).
4. Childless pages bypass chunking; pages with children are chunked via the chunker; all payloads are embedded with VoyageAI and written to Weaviate.
5. Roam extension queries `/search`, which embeds the query with VoyageAI, runs Weaviate hybrid + optional rerank, and returns formatted results with block context.

> **Change detection:** Roam pages do not update their own `:edit/time` when children change, so the pipeline aggregates the maximum block edit timestamp observed while walking each page. Incremental syncs skip a page when its aggregated edit time is not greater than the cached value. A content hash is stored with each write and used to safely delete any stale objects from earlier runs.

> **Childless‑page optimisation:** For pages without children, all content lives in `:node/title`. The pipeline avoids a second Roam pull and the chunker entirely for those pages, embedding and indexing only the page object.

## Prerequisites

### Accounts & API keys
You must provision the following before deploying:
- **Roam graph token** – Generated by a graph admin under *Settings ▸ Graph ▸ API Tokens*. Needs `read+edit` or `read-only` scope. The backend reads from Roam and uses this token for both sync and live context pulls.
- **VoyageAI API key** – Sign up at [https://www.voyageai.com](https://www.voyageai.com) and create an API key that has access to the `voyage-context-3` embedding model and the `rerank-2-lite` reranker. The key is used by:
  - The sync pipeline (`VoyageEmbeddingClient`) for document embeddings.
  - Weaviate reranker module (forwarded via `X-VoyageAI-Api-Key`).
  - The chunker service when `CHUNKER_EMBEDDING_PROVIDER=voyageai`.
- **Google Generative AI key (placeholder acceptable)** – The settings model currently requires `GOOGLE_API_KEY`. The service does not call Google today, so a dummy value such as `dummy` is fine, but the environment variable must exist.

Optional but recommended:
- **Reverse proxy / TLS certificates** if you intend to expose the backend publicly.

### Tooling on the host
- Docker Engine ≥ 24.x
- Docker Compose v2 (`docker compose` CLI)
- Make sure outbound HTTPS is permitted so containers can pull images and the chunker can download the IBM Granite model (or call VoyageAI).

## Configuration

1. Copy `.env` and replace placeholders with your own secrets. Treat this file as sensitive.

   ```bash
   cp .env .env.production
   ```

2. Edit the file and keep only placeholder values, for example:

   ```dotenv
   # Roam API
   ROAM_GRAPH_NAME=your-graph-slug
   ROAM_API_TOKEN=roam-graph-token-XXXXXXXXXXXXXXXXXXXXXXXX

   # Embeddings
   VOYAGEAI_API_KEY=sk-your-voyage-key
   GOOGLE_API_KEY=dummy-or-your-key

   # Service wiring
   WEAVIATE_HTTP_HOST=weaviate
   WEAVIATE_GRPC_HOST=weaviate
   CHUNKER_SERVICE_URL=http://chunker:8003

   # Chunker tuning (optional overrides)
   CHUNKER_EMBEDDING_PROVIDER=voyageai
   CHUNKER_VOYAGE_MODEL=voyage-3-lite
   CHUNKER_MODEL=ibm-granite/granite-embedding-small-english-r2
   CHUNKER_THRESHOLD=0.6
   CHUNKER_CHUNK_SIZE=800
   CHUNKER_SKIP_WINDOW=1
   CHUNKER_MIN_CHUNK_SIZE=50

   # Pipeline tuning (optional)
   ROAM_MAX_REQUESTS_PER_MINUTE=50
   CHUNKER_CONCURRENCY=1
   CHUNKER_GROUP_SIZE=16
   VOYAGE_CONCURRENCY=4
   WEAVIATE_WRITE_CONCURRENCY=1
   SEMANTIC_SYNC_DB=/app/data/semantic_sync.db
   SYNC_STATE_FILE=/app/data/sync_state.json
   ```

   > **Note:** `SEMANTIC_SYNC_DB` and `SYNC_STATE_FILE` default to files under `backend/data/`. Persist that directory to keep incremental state across container restarts.
   > The Docker image installs Python packages into `/opt/venv` (outside `/app`) so the bind‑mounted source code at `/app` does not hide dependencies during local development.

3. Point Docker Compose at your customised env file, e.g. `export COMPOSE_FILE=docker-compose.yml` and `export COMPOSE_ENV_FILE=.env.production`, or rename `.env.production` back to `.env`.

## Deployment Options

### Option 1: Using Pre-Built Images (Recommended)

The fastest way to deploy is using pre-built Docker images from GitHub Container Registry. This skips the 5-10 minute build process and ensures you're running tested, consistent images.

**Quick Start:**
```bash
# Pull pre-built images (optional, will auto-pull on first run)
docker pull ghcr.io/maskys/roam-embeddings-search-backend:latest
docker pull ghcr.io/maskys/roam-embeddings-search-chunker:latest

# Launch with production compose file
docker compose -f docker-compose.prod.yml up -d
```

**Benefits:**
- ✅ No build time required (instant startup)
- ✅ Consistent, tested images
- ✅ Optimized for production (multi-worker backend, no hot-reload)
- ✅ Auto-restart on failures
- ✅ ML models pre-cached in images

**Available Images:**
- Backend/Search API: `ghcr.io/maskys/roam-embeddings-search-backend:latest`
- Chunker Service: `ghcr.io/maskys/roam-embeddings-search-chunker:latest`
- Weaviate: `cr.weaviate.io/semitechnologies/weaviate:1.33.0`

Images are automatically built and published on every push to `main` branch via GitHub Actions.

### Option 2: Building from Source (Development)

If you're modifying the code or prefer to build locally:

1. Build images (first run or after dependency changes):
   ```bash
   docker compose build weaviate chunker backend-semantic
   ```

2. Launch the core services:
   ```bash
   docker compose up -d weaviate chunker backend-semantic
   ```

## Verifying the Deployment

Regardless of which deployment option you chose, verify everything is running correctly:

**Check service health:**
```bash
curl http://localhost:8003/health          # chunker ready
curl http://localhost:8002/                # backend handshake (shows graph + document count)
curl http://localhost:8002/sync/runs       # recent run history from SQLite
docker compose logs -f chunker backend-semantic weaviate
```

**Service endpoints:**
- `weaviate` listens on `8080` (HTTP) and `50051` (gRPC) and stores data in `./weaviate_data`.
- `chunker` exposes port `8003` (`http://localhost:8003/health`).
- `backend-semantic` serves FastAPI on `http://localhost:8002` (container port `8000`).

> **Note:** The first chunker start may download ML models; expect a 1-2 minute delay.

## Populating Weaviate

1. Trigger an initial full sync (requires the chunker to be healthy):
   ```bash
   curl -X POST http://localhost:8002/sync/start \
     -H 'Content-Type: application/json' \
     -d '{"mode": "full", "recreate_collection": true}'
   ```

   - `mode` can be `full`, `since`, or `limit` (test run against the first *n* pages).
   - `recreate_collection` drops and rebuilds `RoamSemanticChunks` – use this for the very first sync.
   - `clear` deletes existing objects before reloading.

2. Monitor progress:
   ```bash
   watch -n5 curl -s http://localhost:8002/sync/status | jq
   ```

   The status feed reports progress events (batches, metadata) and a minimal job summary (processed/updated/skipped/failed + cursor). Detailed timings are available in logs.

3. Cancel a stuck job if needed:
   ```bash
   curl -X POST http://localhost:8002/sync/cancel
   ```

4. Incremental updates:
   - Run `mode: "since"` on a schedule. If you omit the `since` timestamp, the backend reuses the last `max_edit_time` captured in the run summary.
   - Persist `backend/data/` so the SQLite cache (`semantic_sync.db`) can help skip unchanged pages.
   - The `/sync/start` payload accepts `state_file` and `resume` for long-running syncs.

## Installing the Roam extension

1. Open `roam-semantic-search/extension.js` and copy the contents.
2. In Roam, either:
   - Paste the script under a `{{[[roam/js]]}}` block, **or**
   - Host it somewhere (GitHub Gist, CDN) and reference it via a `<script>` tag as per [Roam Depot docs](docs/external/roam_research/roam-extension-docs.md).
3. After the script loads, open the extension settings:
   - Command Palette → “Semantic Search: Open Settings”, or use Roam Depot’s settings pane.
   - Set **Backend URL** to your deployment (e.g. `http://localhost:8002` or your HTTPS domain).
   - Adjust result limits, debounce, and toggles (`Hide Page Results`, `Use VoyageAI Rerank`, `Search Alpha`).
4. Use the built-in buttons to:
   - **Test Connection** – calls `/` and confirms collection count.
   - **Sync Recently Edited Pages / Full Sync** – proxies the `/sync/start` API.
   - **Clear Database** – drops the Weaviate collection via `/sync/clear` (destructive).
5. Launch the search modal: Command Palette → “Semantic Search”. Results support keyboard navigation, filtering, reranking, and linking back to Roam blocks.

## Operating in production

- **Security** – Place the FastAPI service behind an authenticated reverse proxy. Lock down ports 8002 and 8003 to trusted networks. Store API keys in a secrets manager rather than committing them to the repo.
- **TLS** – Terminate HTTPS in a proxy (nginx, Caddy, Traefik) and forward to the backend. Update the extension’s backend URL accordingly.
- **Scheduling syncs** – Use cron or an automation platform to POST to `/sync/start` on intervals (e.g. hourly `since` sync). If you omit the timestamp, the service uses the previous run's cursor.
- **Backups** – Snapshot `weaviate_data/` and `backend/data/` regularly. The latter holds sync history and state.
- **Monitoring** – Watch container logs for `Voyage embedding failed` or Roam API rate-limit messages. Consider scraping `/sync/status` and `uvicorn` metrics.
- **Resource sizing** – Embedding large graphs is CPU and network intensive. Ensure the host has enough CPU/RAM and allows outbound HTTPS calls to `api.roamresearch.com` and `api.voyageai.com`.

## Troubleshooting

- **401 / 403 from Roam** – Re-issue the graph token and verify the `ROAM_GRAPH_NAME` matches the slug shown in the Roam URL. Tokens must be prefixed with `roam-graph-token-` and sent as `Bearer`.
- **VoyageAI errors** – Check quota and model access. If you prefer to avoid API calls in the chunker, switch `CHUNKER_EMBEDDING_PROVIDER=granite` (no API key needed) and restart.
- **Chunker health fails** – First launch downloads models; watch `docker compose logs chunker`. Ensure the container has enough RAM (~2 GB recommended).
- **Weaviate rejects writes** – Confirm the `reranker-voyageai` module is enabled and the FastAPI client is attaching `X-VoyageAI-Api-Key`. Re-run with `recreate_collection` if the schema drifted.
- **Extension cannot reach backend** – Browser must reach your backend URL over HTTPS if Roam is served over HTTPS. Configure CORS or host the backend under the same domain.
- **State not persisting** – Mount `backend/data/` to a durable volume. Otherwise each container restart forces a fresh sync.

## Reference & Further Reading

- Backend source: `backend/` (see `services/search_service.py`, `services/chunker_service.py`, `sync/`, `clients/`, `common/`).
- CLI sync: `backend/cli/sync.py` (run orchestration outside the API if needed).
- Roam extension: `roam-semantic-search/extension.js`.
- Roam API docs: `docs/external/roam_research/roam-backend-api.md`.
- VoyageAI context models: `docs/external/voyageai/context-model-guide.md`.
- Chunker service (`chonkie`) configuration: `backend/services/chunker_service.py`.

Feel free to adapt Docker Compose or deploy the services on your own orchestration platform. The key requirements are:
1. FastAPI backend with the env vars above.
2. Accessible chunker service.
3. Weaviate with `reranker-voyageai` enabled and persistent storage.
4. Roam extension pointing at your backend URL.
